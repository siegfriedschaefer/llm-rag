# RAG (Retrieval Augmented Generation) -LLM System Design Overview

The design of a RAG system envolves two system components:

- a retrieval model to retrieve relevant information from a data source like a database, an API or file collection

- a LLM which you source with the retrieved information to generate contextually relevant responses.

## Motivation

I will build a RAG chatbot with LangChaim which uses (... Neo4j as a Datastore ...).

## Objectives

- use Langchain to build the chatbot

- design the chatbot to use the proposed data as a data source

- (... work with graph databases ...)

- build a RAG chatbot that retrieves structured and unstructured data from (... Neo4j ...)

- Deploy the chatbot with (... FastAPI ...) and (... Streamlit ...)

- develop a REST API which serves the LangChain chatbot

- develop a Streamlit app that provides the chat interface to interact with the REST API.

The Streamlit app sends the user messages to the REST API of the chatbot which generates a response and sends it back to the Streamlit app, which than displays it to the user.

## Technology Stack

- Python
- LLM
- Prompt Engineering
- Text embeddings and (... Neo4j ...)
- (... Graph databases ...) (... Neo4j ...)
- (... OpenAI developer ecosystem ...)
- REST APIs and FastAPI
- Asynchronous programming
- Docker / Docker Compose
